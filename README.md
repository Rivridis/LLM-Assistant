# LLM-Assistant
LLM-Assistant is a browser interface based on Gradio that interfaces with local LLMs to call functions and act as a general assistant.

## Features
* Works with any instruct-finetuned LLM
* Can search for information (RAG)
* Knows when to call functions

## Upcoming Features
* Vector Database
* Function execution support
* Error handling
* GBNF Grammar output structure

## Current Bugs
* Search feature might crash at times
* No error handling, causing the code to crash when LLM produces unparsable output

## Setup
### Setup on Windows 10/11
1. Clone repo to a virtual environment
2. Install requirements.txt
3. Download and place LLM model in model folder
4. Run main.py

## Images
![image](https://github.com/Rivridis/LLM-Assistant/assets/97879757/a93bf7d1-7ede-4908-b643-be46b20df9a6)

